{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.utils import get_project_root\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from typing import List\n",
    "from rich import print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>classid</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nUK house prices dipped slightly in Novembe...</td>\n",
       "      <td>0</td>\n",
       "      <td>UK house prices dip in November</td>\n",
       "      <td>415.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nShares in struggling German football club ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rescue hope for Borussia Dortmund</td>\n",
       "      <td>219.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nIndia's rupee has hit a five-year high aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>India's rupee hits five-year high</td>\n",
       "      <td>018.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nTurkey's investment in Iran's mobile indus...</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey-Iran mobile deal 'at risk'</td>\n",
       "      <td>074.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nTelecoms equipment maker Nortel Networks h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Nortel in $300m profit revision</td>\n",
       "      <td>425.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text  classid  \\\n",
       "0  business  \\n\\nUK house prices dipped slightly in Novembe...        0   \n",
       "1  business  \\n\\nShares in struggling German football club ...        0   \n",
       "2  business  \\n\\nIndia's rupee has hit a five-year high aft...        0   \n",
       "3  business  \\n\\nTurkey's investment in Iran's mobile indus...        0   \n",
       "4  business  \\n\\nTelecoms equipment maker Nortel Networks h...        0   \n",
       "\n",
       "                               title filename  \n",
       "0    UK house prices dip in November  415.txt  \n",
       "1  Rescue hope for Borussia Dortmund  219.txt  \n",
       "2  India's rupee hits five-year high  018.txt  \n",
       "3  Turkey-Iran mobile deal 'at risk'  074.txt  \n",
       "4    Nortel in $300m profit revision  425.txt  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = os.path.join(get_project_root(), 'data', 'bbc')\n",
    "text_path = os.path.join(root_path, 'raw_text')\n",
    "\n",
    "class_id_map = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}\n",
    "\n",
    "df_dict = {\n",
    "    'class': [],\n",
    "    'text': [],\n",
    "    'classid' : [], \n",
    "    'title': [],\n",
    "    'filename': []\n",
    "}\n",
    "\n",
    "def gaussian_pdf(x, variance:np.float128, mean=0):\n",
    "    if not isinstance(x, np.float128) or not isinstance(variance, np.float128) or not isinstance(mean, np.float128):\n",
    "        x = np.float128(x)\n",
    "        variance = np.float128(variance)\n",
    "        mean = np.float128(mean)\n",
    "    return np.float128((1 / np.sqrt(2 * np.pi * variance)) * np.exp(-0.5 * ((x - mean) ** 2) / (variance+0.00001)))\n",
    "\n",
    "# Load the data into dataframe\n",
    "for _class in class_id_map.keys():\n",
    "    _path = os.path.join(text_path, _class)\n",
    "    text_list = os.listdir(_path)\n",
    "    for _text in text_list:\n",
    "        with open(os.path.join(_path, _text), 'r') as f:\n",
    "            text = f.read()\n",
    "        title = text.split('\\n')[0]\n",
    "        text = text.replace(title, '')\n",
    "        df_dict['class'].append(_class)\n",
    "        df_dict['text'].append(text)\n",
    "        df_dict['classid'].append(class_id_map[_class])\n",
    "        df_dict['title'].append(title)\n",
    "        df_dict['filename'].append(_text)\n",
    "\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_words(text: str, use_stemming: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Clean and split words from text.\n",
    "    - Converts text to lowercase.\n",
    "    - Removes special characters and numbers.\n",
    "    - Removes stopwords.\n",
    "    - Optionally applies stemming.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word.strip() for word in words if word not in stop_words]\n",
    "    if use_stemming:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def generate_ngrams(words, ngram_range):\n",
    "    ngrams_list = []\n",
    "    for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngrams_list.append(' '.join(words[i:i + n]))\n",
    "    return ngrams_list\n",
    "\n",
    "class TfIdfVectorizer:\n",
    "    def __init__(self, sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, 2), stop_word_lang='english'):\n",
    "        nltk.download('stopwords')\n",
    "        self.sublinear_tf = sublinear_tf\n",
    "        self.min_df = min_df\n",
    "        self.norm = norm\n",
    "        self.ngram_range = ngram_range\n",
    "        self.stop_words = stopwords.words(stop_word_lang)\n",
    "        self.token_map = {}\n",
    "    \n",
    "    def fit_transform(self, documents: pd.Series) -> np.ndarray:\n",
    "        if self.ngram_range == (1,1):\n",
    "            docs_tokens = [clean_and_split_words(doc) for doc in documents]\n",
    "        else:\n",
    "            docs_tokens = [generate_ngrams(clean_and_split_words(doc), self.ngram_range) for doc in documents]\n",
    "        vocabulary = set(word for doc in docs_tokens for word in doc)\n",
    "        vocab_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "        df = {word: 0 for word in vocabulary}\n",
    "        for tokens in docs_tokens:\n",
    "            unique_tokens = set(tokens)\n",
    "            for token in unique_tokens:\n",
    "                df[token] += 1\n",
    "\n",
    "        total_docs = len(documents)\n",
    "        idf = {word: np.log(total_docs / (df[word] + 1)) + 1 for word in vocabulary}\n",
    "\n",
    "        tf = {word: 0 for word in vocabulary}\n",
    "        for tokens in docs_tokens:\n",
    "            for token in tokens:\n",
    "                tf[token] += 1\n",
    "        \n",
    "        vocab_index = {word: idx for idx, word in enumerate(vocabulary) if tf[word] >= self.min_df}\n",
    "        vocabulary = set(vocab_index.keys())\n",
    "\n",
    "        tfidf_matrix = np.zeros((total_docs, len(vocabulary)))\n",
    "        for doc_idx, tokens in enumerate(docs_tokens):\n",
    "            doc_freq = {word: 0 for word in vocab_index.keys()}\n",
    "            for token in tokens:\n",
    "                if token in vocab_index:\n",
    "                    doc_freq[token] += 1\n",
    "            vector = np.array([doc_freq[word] * idf[word] for word in vocab_index.keys()])\n",
    "            if self.sublinear_tf:\n",
    "                vector = np.log(vector + 1)\n",
    "            tfidf_matrix[doc_idx] = vector\n",
    "\n",
    "        if self.norm == 'l2':\n",
    "            norms = np.linalg.norm(tfidf_matrix, axis=1, keepdims=True)\n",
    "            tfidf_matrix = tfidf_matrix / norms\n",
    "        elif self.norm == 'l1':\n",
    "            norms = np.linalg.norm(tfidf_matrix, ord=1, axis=1, keepdims=True)\n",
    "            tfidf_matrix = tfidf_matrix / norms\n",
    "        elif self.norm == None:\n",
    "            pass\n",
    "        \n",
    "        self.token_map = vocab_index\n",
    "\n",
    "        return tfidf_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nemit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\n",
       " \u001b[33m...\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[33m...\u001b[0m \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m. \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = TfIdfVectorizer(norm=None, ngram_range=(1,2))\n",
    "texts = df['text']\n",
    "features = vectorizer.fit_transform(texts)\n",
    "features.shape\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'token_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m features\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_map\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vectorizer\u001b[38;5;241m.\u001b[39mtoken_map))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'token_map'"
     ]
    }
   ],
   "source": [
    "features.shape\n",
    "vectorizer.token_map\n",
    "print(len(vectorizer.token_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># <span style=\"color: #008000; text-decoration-color: #008000\">'business'</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# \u001b[32m'business'\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated unigrams:\n",
       "       . bank\n",
       "       . oil\n",
       "       . growth\n",
       "       . shares\n",
       "       . bn\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated unigrams:\n",
       "       . bank\n",
       "       . oil\n",
       "       . growth\n",
       "       . shares\n",
       "       . bn\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated bigrams:\n",
       "       . oil prices\n",
       "       . economic growth\n",
       "       . stock market\n",
       "       . analysts said\n",
       "       . bn bn\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated bigrams:\n",
       "       . oil prices\n",
       "       . economic growth\n",
       "       . stock market\n",
       "       . analysts said\n",
       "       . bn bn\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># <span style=\"color: #008000; text-decoration-color: #008000\">'entertainment'</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# \u001b[32m'entertainment'\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated unigrams:\n",
       "       . singer\n",
       "       . award\n",
       "       . actor\n",
       "       . awards\n",
       "       . film\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated unigrams:\n",
       "       . singer\n",
       "       . award\n",
       "       . actor\n",
       "       . awards\n",
       "       . film\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated bigrams:\n",
       "       . named best\n",
       "       . million dollar\n",
       "       . best film\n",
       "       . los angeles\n",
       "       . box office\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated bigrams:\n",
       "       . named best\n",
       "       . million dollar\n",
       "       . best film\n",
       "       . los angeles\n",
       "       . box office\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># <span style=\"color: #008000; text-decoration-color: #008000\">'politics'</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# \u001b[32m'politics'\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated unigrams:\n",
       "       . tory\n",
       "       . party\n",
       "       . blair\n",
       "       . election\n",
       "       . labour\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated unigrams:\n",
       "       . tory\n",
       "       . party\n",
       "       . blair\n",
       "       . election\n",
       "       . labour\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated bigrams:\n",
       "       . michael howard\n",
       "       . general election\n",
       "       . prime minister\n",
       "       . tony blair\n",
       "       . mr blair\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated bigrams:\n",
       "       . michael howard\n",
       "       . general election\n",
       "       . prime minister\n",
       "       . tony blair\n",
       "       . mr blair\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># <span style=\"color: #008000; text-decoration-color: #008000\">'sport'</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# \u001b[32m'sport'\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated unigrams:\n",
       "       . win\n",
       "       . injury\n",
       "       . match\n",
       "       . coach\n",
       "       . cup\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated unigrams:\n",
       "       . win\n",
       "       . injury\n",
       "       . match\n",
       "       . coach\n",
       "       . cup\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated bigrams:\n",
       "       . champions league\n",
       "       . bbc sport\n",
       "       . year old\n",
       "       . grand slam\n",
       "       . six nations\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated bigrams:\n",
       "       . champions league\n",
       "       . bbc sport\n",
       "       . year old\n",
       "       . grand slam\n",
       "       . six nations\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># <span style=\"color: #008000; text-decoration-color: #008000\">'tech'</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# \u001b[32m'tech'\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated unigrams:\n",
       "       . digital\n",
       "       . computer\n",
       "       . software\n",
       "       . technology\n",
       "       . users\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated unigrams:\n",
       "       . digital\n",
       "       . computer\n",
       "       . software\n",
       "       . technology\n",
       "       . users\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  . Most correlated bigrams:\n",
       "       . high definition\n",
       "       . mobile phones\n",
       "       . mobile phone\n",
       "       . news website\n",
       "       . e mail\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  . Most correlated bigrams:\n",
       "       . high definition\n",
       "       . mobile phones\n",
       "       . mobile phone\n",
       "       . news website\n",
       "       . e mail\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 5\n",
    "for category, category_id in sorted(class_id_map.items()):\n",
    "    features_chi2 = chi2(features, df['classid'] == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(list(vectorizer.token_map.keys()))[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding']=list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>classid</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nUK house prices dipped slightly in Novembe...</td>\n",
       "      <td>0</td>\n",
       "      <td>UK house prices dip in November</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nShares in struggling German football club ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rescue hope for Borussia Dortmund</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>018.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nIndia's rupee has hit a five-year high aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>India's rupee hits five-year high</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>074.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nTurkey's investment in Iran's mobile indus...</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey-Iran mobile deal 'at risk'</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nTelecoms equipment maker Nortel Networks h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Nortel in $300m profit revision</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class                                               text  \\\n",
       "filename                                                                \n",
       "415.txt   business  \\n\\nUK house prices dipped slightly in Novembe...   \n",
       "219.txt   business  \\n\\nShares in struggling German football club ...   \n",
       "018.txt   business  \\n\\nIndia's rupee has hit a five-year high aft...   \n",
       "074.txt   business  \\n\\nTurkey's investment in Iran's mobile indus...   \n",
       "425.txt   business  \\n\\nTelecoms equipment maker Nortel Networks h...   \n",
       "\n",
       "          classid                              title  \\\n",
       "filename                                               \n",
       "415.txt         0    UK house prices dip in November   \n",
       "219.txt         0  Rescue hope for Borussia Dortmund   \n",
       "018.txt         0  India's rupee hits five-year high   \n",
       "074.txt         0  Turkey-Iran mobile deal 'at risk'   \n",
       "425.txt         0    Nortel in $300m profit revision   \n",
       "\n",
       "                                                  embedding  \n",
       "filename                                                     \n",
       "415.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "219.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "018.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "074.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "425.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('filename', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classid</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.009567258650722172686, 0.033088098007264053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.01289227313261250181, 0.0111468920335946949...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.011808238154494934621, 0.035733655392979984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.15227987983290089402, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.026515187491250237495, 0.031873144408559830...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classid                                           centroid\n",
       "0        0  [0.009567258650722172686, 0.033088098007264053...\n",
       "1        1  [0.01289227313261250181, 0.0111468920335946949...\n",
       "2        2  [0.011808238154494934621, 0.035733655392979984...\n",
       "3        3  [0.0, 0.15227987983290089402, 0.0, 0.0, 0.0, 0...\n",
       "4        4  [0.026515187491250237495, 0.031873144408559830..."
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start calculating centroind and variance from test dataset\n",
    "if isinstance(df.iloc[0]['embedding'], list):\n",
    "    df['embedding'] = df['embedding'].apply(lambda x: np.array(x, dtype=np.float128))\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "train_size = int(len(df) * train_test_ratio)\n",
    "# Shuffle dataset\n",
    "df = df.sample(frac=1)\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "centroid_df = train_df.groupby('classid')['embedding'].apply(lambda x: np.mean(np.stack(x), axis=0)).reset_index()\n",
    "\n",
    "centroid_df['embedding'] = centroid_df['embedding'].apply(lambda x: np.array(x, dtype=np.float128))\n",
    "\n",
    "centroid_df.columns = ['classid', 'centroid']\n",
    "\n",
    "centroid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>classid</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance_to_centroid_0</th>\n",
       "      <th>distance_to_centroid_1</th>\n",
       "      <th>distance_to_centroid_2</th>\n",
       "      <th>distance_to_centroid_3</th>\n",
       "      <th>distance_to_centroid_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198.txt</th>\n",
       "      <td>tech</td>\n",
       "      <td>\\n\\nAnalyst Bill Thompson has seen the future ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Musical future for phones</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>36.150746</td>\n",
       "      <td>36.056102</td>\n",
       "      <td>36.122372</td>\n",
       "      <td>36.103184</td>\n",
       "      <td>34.295932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>085.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nRoman Catholic organisations in India have...</td>\n",
       "      <td>1</td>\n",
       "      <td>Church anger over Bollywood film</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>22.901564</td>\n",
       "      <td>22.479282</td>\n",
       "      <td>22.902032</td>\n",
       "      <td>23.062860</td>\n",
       "      <td>23.102874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nAlbania, Bulgaria and Macedonia has given ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Go-ahead for Balkan oil pipeline</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.126090</td>\n",
       "      <td>19.613763</td>\n",
       "      <td>19.858996</td>\n",
       "      <td>19.694255</td>\n",
       "      <td>20.064475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nHollywood stars brought a touch of glamour...</td>\n",
       "      <td>1</td>\n",
       "      <td>Stars shine on Bafta red carpet</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>31.231711</td>\n",
       "      <td>29.763306</td>\n",
       "      <td>31.251330</td>\n",
       "      <td>30.901229</td>\n",
       "      <td>31.154295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nThe US Vibe awards will be held again next...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vibe awards back despite violence</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>18.735009</td>\n",
       "      <td>18.224808</td>\n",
       "      <td>19.196691</td>\n",
       "      <td>18.831762</td>\n",
       "      <td>19.370019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class                                               text  \\\n",
       "filename                                                                     \n",
       "198.txt            tech  \\n\\nAnalyst Bill Thompson has seen the future ...   \n",
       "085.txt   entertainment  \\n\\nRoman Catholic organisations in India have...   \n",
       "363.txt        business  \\n\\nAlbania, Bulgaria and Macedonia has given ...   \n",
       "354.txt   entertainment  \\n\\nHollywood stars brought a touch of glamour...   \n",
       "135.txt   entertainment  \\n\\nThe US Vibe awards will be held again next...   \n",
       "\n",
       "          classid                              title  \\\n",
       "filename                                               \n",
       "198.txt         4          Musical future for phones   \n",
       "085.txt         1   Church anger over Bollywood film   \n",
       "363.txt         0   Go-ahead for Balkan oil pipeline   \n",
       "354.txt         1    Stars shine on Bafta red carpet   \n",
       "135.txt         1  Vibe awards back despite violence   \n",
       "\n",
       "                                                  embedding  \\\n",
       "filename                                                      \n",
       "198.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "085.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "363.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "354.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "135.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "          distance_to_centroid_0  distance_to_centroid_1  \\\n",
       "filename                                                   \n",
       "198.txt                36.150746               36.056102   \n",
       "085.txt                22.901564               22.479282   \n",
       "363.txt                19.126090               19.613763   \n",
       "354.txt                31.231711               29.763306   \n",
       "135.txt                18.735009               18.224808   \n",
       "\n",
       "          distance_to_centroid_2  distance_to_centroid_3  \\\n",
       "filename                                                   \n",
       "198.txt                36.122372               36.103184   \n",
       "085.txt                22.902032               23.062860   \n",
       "363.txt                19.858996               19.694255   \n",
       "354.txt                31.251330               30.901229   \n",
       "135.txt                19.196691               18.831762   \n",
       "\n",
       "          distance_to_centroid_4  \n",
       "filename                          \n",
       "198.txt                34.295932  \n",
       "085.txt                23.102874  \n",
       "363.txt                20.064475  \n",
       "354.txt                31.154295  \n",
       "135.txt                19.370019  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.copy()\n",
    "\n",
    "df['distance_to_centroid_0'] = df['embedding'].apply(lambda x: np.float128(np.linalg.norm(x - centroid_df.loc[0]['centroid'])))\n",
    "df['distance_to_centroid_1'] = df['embedding'].apply(lambda x: np.float128(np.linalg.norm(x - centroid_df.loc[1]['centroid'])))\n",
    "df['distance_to_centroid_2'] = df['embedding'].apply(lambda x: np.float128(np.linalg.norm(x - centroid_df.loc[2]['centroid'])))\n",
    "df['distance_to_centroid_3'] = df['embedding'].apply(lambda x: np.float128(np.linalg.norm(x - centroid_df.loc[3]['centroid'])))\n",
    "df['distance_to_centroid_4'] = df['embedding'].apply(lambda x: np.float128(np.linalg.norm(x - centroid_df.loc[4]['centroid'])))\n",
    "\n",
    "\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classid</th>\n",
       "      <th>centroid</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.009567258650722172686, 0.033088098007264053...</td>\n",
       "      <td>16.962785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.01289227313261250181, 0.0111468920335946949...</td>\n",
       "      <td>27.489168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.011808238154494934621, 0.035733655392979984...</td>\n",
       "      <td>29.440864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.15227987983290089402, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>29.114598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.026515187491250237495, 0.031873144408559830...</td>\n",
       "      <td>22.808816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classid                                           centroid   variance\n",
       "0        0  [0.009567258650722172686, 0.033088098007264053...  16.962785\n",
       "1        1  [0.01289227313261250181, 0.0111468920335946949...  27.489168\n",
       "2        2  [0.011808238154494934621, 0.035733655392979984...  29.440864\n",
       "3        3  [0.0, 0.15227987983290089402, 0.0, 0.0, 0.0, 0...  29.114598\n",
       "4        4  [0.026515187491250237495, 0.031873144408559830...  22.808816"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Filter df for the current category\n",
    "    category_mask = train_df['classid'] == i\n",
    "    \n",
    "    # Calculate variance of 'distance_to_centroid_i' for this category\n",
    "    variance = np.var(train_df.loc[category_mask, f\"distance_to_centroid_{i}\"])\n",
    "    \n",
    "    # Assign calculated variance to the correct entry in centroid_df\n",
    "    centroid_df.loc[centroid_df['classid'] == i, 'variance'] = np.var(train_df.loc[category_mask, f\"distance_to_centroid_{i}\"])\n",
    "\n",
    "centroid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pmf_cat0'] = df['distance_to_centroid_0'].apply(lambda x: float(gaussian_pdf(x, centroid_df.iloc[0]['variance'])))\n",
    "df['pmf_cat1'] = df['distance_to_centroid_1'].apply(lambda x: float(gaussian_pdf(x, centroid_df.iloc[1]['variance'])))\n",
    "df['pmf_cat2'] = df['distance_to_centroid_2'].apply(lambda x: float(gaussian_pdf(x, centroid_df.iloc[2]['variance'])))\n",
    "df['pmf_cat3'] = df['distance_to_centroid_3'].apply(lambda x: float(gaussian_pdf(x, centroid_df.iloc[3]['variance'])))\n",
    "df['pmf_cat4'] = df['distance_to_centroid_4'].apply(lambda x: float(gaussian_pdf(x, centroid_df.iloc[4]['variance'])))\n",
    "\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>classid</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance_to_centroid_0</th>\n",
       "      <th>distance_to_centroid_1</th>\n",
       "      <th>distance_to_centroid_2</th>\n",
       "      <th>distance_to_centroid_3</th>\n",
       "      <th>distance_to_centroid_4</th>\n",
       "      <th>pmf_cat0</th>\n",
       "      <th>pmf_cat1</th>\n",
       "      <th>pmf_cat2</th>\n",
       "      <th>pmf_cat3</th>\n",
       "      <th>pmf_cat4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198.txt</th>\n",
       "      <td>tech</td>\n",
       "      <td>\\n\\nAnalyst Bill Thompson has seen the future ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Musical future for phones</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>36.150746</td>\n",
       "      <td>36.056102</td>\n",
       "      <td>36.122372</td>\n",
       "      <td>36.103184</td>\n",
       "      <td>34.295932</td>\n",
       "      <td>1.804412e-18</td>\n",
       "      <td>4.090817e-12</td>\n",
       "      <td>1.747525e-11</td>\n",
       "      <td>1.403880e-11</td>\n",
       "      <td>5.296125e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>085.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nRoman Catholic organisations in India have...</td>\n",
       "      <td>1</td>\n",
       "      <td>Church anger over Bollywood film</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>22.901564</td>\n",
       "      <td>22.479282</td>\n",
       "      <td>22.902032</td>\n",
       "      <td>23.062860</td>\n",
       "      <td>23.102874</td>\n",
       "      <td>1.870988e-08</td>\n",
       "      <td>7.755922e-06</td>\n",
       "      <td>9.950712e-06</td>\n",
       "      <td>7.976022e-06</td>\n",
       "      <td>6.925621e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nAlbania, Bulgaria and Macedonia has given ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Go-ahead for Balkan oil pipeline</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.126090</td>\n",
       "      <td>19.613763</td>\n",
       "      <td>19.858996</td>\n",
       "      <td>19.694255</td>\n",
       "      <td>20.064475</td>\n",
       "      <td>2.010581e-06</td>\n",
       "      <td>6.957341e-05</td>\n",
       "      <td>9.069966e-05</td>\n",
       "      <td>9.462972e-05</td>\n",
       "      <td>1.227834e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nHollywood stars brought a touch of glamour...</td>\n",
       "      <td>1</td>\n",
       "      <td>Stars shine on Bafta red carpet</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>31.231711</td>\n",
       "      <td>29.763306</td>\n",
       "      <td>31.251330</td>\n",
       "      <td>30.901229</td>\n",
       "      <td>31.154295</td>\n",
       "      <td>3.158196e-14</td>\n",
       "      <td>7.649557e-09</td>\n",
       "      <td>4.602390e-09</td>\n",
       "      <td>5.584332e-09</td>\n",
       "      <td>4.803235e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135.txt</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>\\n\\nThe US Vibe awards will be held again next...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vibe awards back despite violence</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>18.735009</td>\n",
       "      <td>18.224808</td>\n",
       "      <td>19.196691</td>\n",
       "      <td>18.831762</td>\n",
       "      <td>19.370019</td>\n",
       "      <td>3.110777e-06</td>\n",
       "      <td>1.809686e-04</td>\n",
       "      <td>1.407315e-04</td>\n",
       "      <td>1.674391e-04</td>\n",
       "      <td>2.237992e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class                                               text  \\\n",
       "filename                                                                     \n",
       "198.txt            tech  \\n\\nAnalyst Bill Thompson has seen the future ...   \n",
       "085.txt   entertainment  \\n\\nRoman Catholic organisations in India have...   \n",
       "363.txt        business  \\n\\nAlbania, Bulgaria and Macedonia has given ...   \n",
       "354.txt   entertainment  \\n\\nHollywood stars brought a touch of glamour...   \n",
       "135.txt   entertainment  \\n\\nThe US Vibe awards will be held again next...   \n",
       "\n",
       "          classid                              title  \\\n",
       "filename                                               \n",
       "198.txt         4          Musical future for phones   \n",
       "085.txt         1   Church anger over Bollywood film   \n",
       "363.txt         0   Go-ahead for Balkan oil pipeline   \n",
       "354.txt         1    Stars shine on Bafta red carpet   \n",
       "135.txt         1  Vibe awards back despite violence   \n",
       "\n",
       "                                                  embedding  \\\n",
       "filename                                                      \n",
       "198.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "085.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "363.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "354.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "135.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "          distance_to_centroid_0  distance_to_centroid_1  \\\n",
       "filename                                                   \n",
       "198.txt                36.150746               36.056102   \n",
       "085.txt                22.901564               22.479282   \n",
       "363.txt                19.126090               19.613763   \n",
       "354.txt                31.231711               29.763306   \n",
       "135.txt                18.735009               18.224808   \n",
       "\n",
       "          distance_to_centroid_2  distance_to_centroid_3  \\\n",
       "filename                                                   \n",
       "198.txt                36.122372               36.103184   \n",
       "085.txt                22.902032               23.062860   \n",
       "363.txt                19.858996               19.694255   \n",
       "354.txt                31.251330               30.901229   \n",
       "135.txt                19.196691               18.831762   \n",
       "\n",
       "          distance_to_centroid_4      pmf_cat0      pmf_cat1      pmf_cat2  \\\n",
       "filename                                                                     \n",
       "198.txt                34.295932  1.804412e-18  4.090817e-12  1.747525e-11   \n",
       "085.txt                23.102874  1.870988e-08  7.755922e-06  9.950712e-06   \n",
       "363.txt                20.064475  2.010581e-06  6.957341e-05  9.069966e-05   \n",
       "354.txt                31.154295  3.158196e-14  7.649557e-09  4.602390e-09   \n",
       "135.txt                19.370019  3.110777e-06  1.809686e-04  1.407315e-04   \n",
       "\n",
       "              pmf_cat3      pmf_cat4  \n",
       "filename                              \n",
       "198.txt   1.403880e-11  5.296125e-13  \n",
       "085.txt   7.976022e-06  6.925621e-07  \n",
       "363.txt   9.462972e-05  1.227834e-05  \n",
       "354.txt   5.584332e-09  4.803235e-11  \n",
       "135.txt   1.674391e-04  2.237992e-05  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classid</th>\n",
       "      <th>closest_centroid</th>\n",
       "      <th>pmf_predict</th>\n",
       "      <th>distance_correct</th>\n",
       "      <th>pmf_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>016.txt</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>043.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323.txt</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          classid  closest_centroid  pmf_predict  distance_correct  \\\n",
       "filename                                                             \n",
       "016.txt         4                 4            2                 1   \n",
       "043.txt         0                 0            2                 1   \n",
       "323.txt         4                 4            2                 1   \n",
       "323.txt         0                 0            2                 1   \n",
       "436.txt         0                 0            3                 1   \n",
       "\n",
       "          pmf_correct  \n",
       "filename               \n",
       "016.txt             0  \n",
       "043.txt             0  \n",
       "323.txt             0  \n",
       "323.txt             0  \n",
       "436.txt             0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy().iloc[train_size:]\n",
    "distance_cols = [col for col in data.columns if \"distance_to_centroid_\" in col]\n",
    "pmf_cols = [col for col in data.columns if \"pmf_cat\" in col]\n",
    "\n",
    "# Task 1: Finding the closest centroid\n",
    "data['closest_centroid'] = data[distance_cols].idxmin(axis=1).str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Task 2: Finding the PMF category with the highest probability\n",
    "data['pmf_predict'] = data[pmf_cols].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Task 3: Comparison Columns\n",
    "data['distance_correct'] = (data['closest_centroid'] == data['classid']).astype(int)\n",
    "data['pmf_correct'] = (data['pmf_predict'] == data['classid']).astype(int)\n",
    "\n",
    "# Displaying the updated DataFrame with the new columns\n",
    "data[['classid', 'closest_centroid', 'pmf_predict', 'distance_correct', 'pmf_correct']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy of distance-based classification: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accuracy of distance-based classification: \u001b[1;36m0.95\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy of PMF-based classification: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.51</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accuracy of PMF-based classification: \u001b[1;36m0.51\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distance_accuracy = data['distance_correct'].mean()\n",
    "pmf_col_accuracy = data['pmf_correct'].mean()\n",
    "print(f\"Accuracy of distance-based classification: {distance_accuracy:.2f}\")\n",
    "print(f\"Accuracy of PMF-based classification: {pmf_col_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>classid</th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance_to_centroid_0</th>\n",
       "      <th>distance_to_centroid_1</th>\n",
       "      <th>distance_to_centroid_2</th>\n",
       "      <th>distance_to_centroid_3</th>\n",
       "      <th>distance_to_centroid_4</th>\n",
       "      <th>...</th>\n",
       "      <th>pmf_cat1</th>\n",
       "      <th>pmf_cat2</th>\n",
       "      <th>pmf_cat3</th>\n",
       "      <th>pmf_cat4</th>\n",
       "      <th>closest_centroid</th>\n",
       "      <th>pmf_predict</th>\n",
       "      <th>distance_correct</th>\n",
       "      <th>pmf_correct</th>\n",
       "      <th>top2_distance</th>\n",
       "      <th>top2_pmf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>016.txt</th>\n",
       "      <td>tech</td>\n",
       "      <td>\\n\\nThe global web blog community is being cal...</td>\n",
       "      <td>4</td>\n",
       "      <td>Global blogger action day called</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>29.990901</td>\n",
       "      <td>30.049714</td>\n",
       "      <td>29.728323</td>\n",
       "      <td>30.141487</td>\n",
       "      <td>29.199021</td>\n",
       "      <td>...</td>\n",
       "      <td>5.601604e-09</td>\n",
       "      <td>2.228349e-08</td>\n",
       "      <td>1.238412e-08</td>\n",
       "      <td>6.382641e-10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 2]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>043.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nWomen will be employed in Saudi Arabia's f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi ministry to employ women</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>17.644374</td>\n",
       "      <td>17.796231</td>\n",
       "      <td>17.822547</td>\n",
       "      <td>17.792799</td>\n",
       "      <td>18.445394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.396360e-04</td>\n",
       "      <td>3.338811e-04</td>\n",
       "      <td>3.218544e-04</td>\n",
       "      <td>4.816563e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323.txt</th>\n",
       "      <td>tech</td>\n",
       "      <td>\\n\\nA blind student has developed software tha...</td>\n",
       "      <td>4</td>\n",
       "      <td>Blind student 'hears in colour'</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>24.606260</td>\n",
       "      <td>24.421798</td>\n",
       "      <td>24.676457</td>\n",
       "      <td>24.679667</td>\n",
       "      <td>24.144095</td>\n",
       "      <td>...</td>\n",
       "      <td>1.478947e-06</td>\n",
       "      <td>2.372270e-06</td>\n",
       "      <td>2.118713e-06</td>\n",
       "      <td>2.355650e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nA swathe of figures have provided further ...</td>\n",
       "      <td>0</td>\n",
       "      <td>No seasonal lift for house market</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>25.427523</td>\n",
       "      <td>26.054320</td>\n",
       "      <td>26.186465</td>\n",
       "      <td>26.190864</td>\n",
       "      <td>26.123701</td>\n",
       "      <td>...</td>\n",
       "      <td>3.303831e-07</td>\n",
       "      <td>6.437017e-07</td>\n",
       "      <td>5.658583e-07</td>\n",
       "      <td>2.659133e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436.txt</th>\n",
       "      <td>business</td>\n",
       "      <td>\\n\\nThe European Central Bank has left its key...</td>\n",
       "      <td>0</td>\n",
       "      <td>ECB holds rates amid growth fears</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>21.188282</td>\n",
       "      <td>22.368311</td>\n",
       "      <td>22.592438</td>\n",
       "      <td>22.290552</td>\n",
       "      <td>22.637971</td>\n",
       "      <td>...</td>\n",
       "      <td>8.490767e-06</td>\n",
       "      <td>1.263978e-05</td>\n",
       "      <td>1.455555e-05</td>\n",
       "      <td>1.103847e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[3, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class                                               text  \\\n",
       "filename                                                                \n",
       "016.txt       tech  \\n\\nThe global web blog community is being cal...   \n",
       "043.txt   business  \\n\\nWomen will be employed in Saudi Arabia's f...   \n",
       "323.txt       tech  \\n\\nA blind student has developed software tha...   \n",
       "323.txt   business  \\n\\nA swathe of figures have provided further ...   \n",
       "436.txt   business  \\n\\nThe European Central Bank has left its key...   \n",
       "\n",
       "          classid                              title  \\\n",
       "filename                                               \n",
       "016.txt         4   Global blogger action day called   \n",
       "043.txt         0     Saudi ministry to employ women   \n",
       "323.txt         4    Blind student 'hears in colour'   \n",
       "323.txt         0  No seasonal lift for house market   \n",
       "436.txt         0  ECB holds rates amid growth fears   \n",
       "\n",
       "                                                  embedding  \\\n",
       "filename                                                      \n",
       "016.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "043.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "323.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "323.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "436.txt   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "          distance_to_centroid_0  distance_to_centroid_1  \\\n",
       "filename                                                   \n",
       "016.txt                29.990901               30.049714   \n",
       "043.txt                17.644374               17.796231   \n",
       "323.txt                24.606260               24.421798   \n",
       "323.txt                25.427523               26.054320   \n",
       "436.txt                21.188282               22.368311   \n",
       "\n",
       "          distance_to_centroid_2  distance_to_centroid_3  \\\n",
       "filename                                                   \n",
       "016.txt                29.728323               30.141487   \n",
       "043.txt                17.822547               17.792799   \n",
       "323.txt                24.676457               24.679667   \n",
       "323.txt                26.186465               26.190864   \n",
       "436.txt                22.592438               22.290552   \n",
       "\n",
       "          distance_to_centroid_4  ...      pmf_cat1      pmf_cat2  \\\n",
       "filename                          ...                               \n",
       "016.txt                29.199021  ...  5.601604e-09  2.228349e-08   \n",
       "043.txt                18.445394  ...  2.396360e-04  3.338811e-04   \n",
       "323.txt                24.144095  ...  1.478947e-06  2.372270e-06   \n",
       "323.txt                26.123701  ...  3.303831e-07  6.437017e-07   \n",
       "436.txt                22.637971  ...  8.490767e-06  1.263978e-05   \n",
       "\n",
       "              pmf_cat3      pmf_cat4  closest_centroid  pmf_predict  \\\n",
       "filename                                                              \n",
       "016.txt   1.238412e-08  6.382641e-10                 4            2   \n",
       "043.txt   3.218544e-04  4.816563e-05                 0            2   \n",
       "323.txt   2.118713e-06  2.355650e-07                 4            2   \n",
       "323.txt   5.658583e-07  2.659133e-08                 0            2   \n",
       "436.txt   1.455555e-05  1.103847e-06                 0            3   \n",
       "\n",
       "          distance_correct  pmf_correct  top2_distance top2_pmf  \n",
       "filename                                                         \n",
       "016.txt                  1            0         [4, 2]   [2, 3]  \n",
       "043.txt                  1            0         [0, 3]   [2, 3]  \n",
       "323.txt                  1            0         [4, 1]   [2, 3]  \n",
       "323.txt                  1            0         [0, 1]   [2, 3]  \n",
       "436.txt                  1            0         [0, 3]   [3, 2]  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['top2_distance'] = data[distance_cols].apply(lambda x: list(np.argsort(x.values)[:2]), axis=1)\n",
    "\n",
    "# Task 2: Top 2 categories based on PMF\n",
    "data['top2_pmf'] = data[pmf_cols].apply(lambda x: list(np.argsort(-x.values)[:2]), axis=1)\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
